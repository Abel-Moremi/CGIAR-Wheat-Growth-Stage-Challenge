{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapted from Pytorch transfer learning [tutorial]( https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image, ExifTags\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wheat(Dataset):\n",
    "    def __init__(self, imgs, gts, split_type, transform):\n",
    "        self.imgs = imgs\n",
    "        self.gts = gts\n",
    "                   \n",
    "        self.split_type = split_type\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.imgs[idx]\n",
    "        if self.split_type == 'test':\n",
    "            y = 0\n",
    "        else:\n",
    "            y = self.gts[idx]\n",
    "        img = Image.fromarray(img)\n",
    "        img = self.transform(img)\n",
    "        return img, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(imgs_path, lbl_path):\n",
    "    lbl_df = pd.read_csv(lbl_path)\n",
    "    gt = lbl_df['growth_stage'].to_numpy().astype(np.float32)\n",
    "    lbl_quality = lbl_df['label_quality'].to_numpy()\n",
    "    train_imgs_fname_set = lbl_df['UID'].tolist()\n",
    "    \n",
    "    imgs_fname_arr = os.listdir(imgs_path)\n",
    "    test_id_arr = []\n",
    "    imgs_arr = np.zeros((lbl_df.shape[0], 224, 224, 3), dtype = np.uint8)\n",
    "    test_imgs_arr = np.zeros((len(imgs_fname_arr) - lbl_df.shape[0], 224, 224, 3), dtype = np.uint8)\n",
    "    \n",
    "    i = 0\n",
    "    j = 0\n",
    "    for fname in tqdm(imgs_fname_arr):\n",
    "        img = np.array(Image.open(os.path.join(imgs_path, fname)).convert('RGB').resize((224,224), Image.ANTIALIAS)).astype(np.uint8)\n",
    "        img_id = fname.split('.')[0] \n",
    "        if img_id in train_imgs_fname_set:\n",
    "            imgs_arr[i] = img\n",
    "            i += 1\n",
    "        else:\n",
    "            test_imgs_arr[j] = img\n",
    "            j += 1\n",
    "            test_id_arr.append(img_id)\n",
    "            \n",
    "    return imgs_arr, test_imgs_arr, gt, lbl_quality, test_id_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14253/14253 [00:27<00:00, 524.78it/s]\n"
     ]
    }
   ],
   "source": [
    "#change imgs_path and lbl_path with your paths\n",
    "imgs_arr, test_imgs_arr, gt, lbl_quality, test_id_arr = read_dataset('Images/', 'Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use only high quality data\n",
    "imgs_arr = imgs_arr[lbl_quality == 2]\n",
    "gt = gt[lbl_quality == 2]\n",
    "lbl_quality = lbl_quality[lbl_quality == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, device, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 1000000.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels.unsqueeze(1))\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "\n",
    "            print('{} RMSE Loss: {:.4f}'.format(\n",
    "                phase, np.sqrt(epoch_loss)))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val RMSE Loss: {:4f}'.format(np.sqrt(best_loss)))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into 80% training and 20% validation\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=1234)\n",
    "\n",
    "for train_index, val_index in sss.split(imgs_arr, gt):\n",
    "    break\n",
    "\n",
    "train_imgs_arr = imgs_arr[train_index]\n",
    "train_gt = gt[train_index]\n",
    "val_imgs_arr = imgs_arr[val_index]\n",
    "val_gt = gt[val_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "image_datasets = {'train': Wheat(train_imgs_arr, train_gt, 'train', data_transforms['train']),\n",
    "                  'val': Wheat(val_imgs_arr, val_gt, 'val', data_transforms['val'])}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train RMSE Loss: 2.0236\n",
      "val RMSE Loss: 1.5913\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train RMSE Loss: 1.6818\n",
      "val RMSE Loss: 1.5005\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train RMSE Loss: 1.5660\n",
      "val RMSE Loss: 1.4713\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train RMSE Loss: 1.6002\n",
      "val RMSE Loss: 1.5166\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train RMSE Loss: 1.5240\n",
      "val RMSE Loss: 1.4410\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train RMSE Loss: 1.5208\n",
      "val RMSE Loss: 1.5904\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train RMSE Loss: 1.5028\n",
      "val RMSE Loss: 1.4197\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train RMSE Loss: 1.4240\n",
      "val RMSE Loss: 1.4553\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train RMSE Loss: 1.4285\n",
      "val RMSE Loss: 1.4369\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train RMSE Loss: 1.4247\n",
      "val RMSE Loss: 1.4227\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train RMSE Loss: 1.4310\n",
      "val RMSE Loss: 1.4480\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train RMSE Loss: 1.4241\n",
      "val RMSE Loss: 1.4296\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train RMSE Loss: 1.4291\n",
      "val RMSE Loss: 1.4664\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train RMSE Loss: 1.4263\n",
      "val RMSE Loss: 1.4370\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train RMSE Loss: 1.4200\n",
      "val RMSE Loss: 1.4260\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train RMSE Loss: 1.4144\n",
      "val RMSE Loss: 1.4293\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train RMSE Loss: 1.4164\n",
      "val RMSE Loss: 1.4307\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train RMSE Loss: 1.4147\n",
      "val RMSE Loss: 1.4283\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train RMSE Loss: 1.4186\n",
      "val RMSE Loss: 1.4334\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train RMSE Loss: 1.4164\n",
      "val RMSE Loss: 1.4312\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train RMSE Loss: 1.4176\n",
      "val RMSE Loss: 1.4297\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train RMSE Loss: 1.4166\n",
      "val RMSE Loss: 1.4249\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train RMSE Loss: 1.4170\n",
      "val RMSE Loss: 1.4257\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train RMSE Loss: 1.4159\n",
      "val RMSE Loss: 1.4272\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train RMSE Loss: 1.4162\n",
      "val RMSE Loss: 1.4302\n",
      "\n",
      "Training complete in 3m 12s\n",
      "Best val RMSE Loss: 1.419669\n"
     ]
    }
   ],
   "source": [
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "model_ft.fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, device,\n",
    "                       num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, device):\n",
    "    model.eval()\n",
    "    res_arr = []\n",
    "    for inputs, _ in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)   \n",
    "            res_arr.append(outputs.detach().cpu().numpy())\n",
    "    res_arr = np.concatenate(res_arr, axis = 0)\n",
    "    return res_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets['test'] = Wheat(test_imgs_arr, None, 'test', data_transforms['val'])\n",
    "test_loader = torch.utils.data.DataLoader(image_datasets['test'], batch_size=4,shuffle=False, num_workers=16)\n",
    "test_pred = test(model_ft, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('SampleSubmission.csv')\n",
    "sub['UID'] = test_id_arr\n",
    "sub['growth_stage'] = test_pred.flatten().tolist()\n",
    "sub.to_csv('high_quality_data_resnet18_sub.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
